{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from test_utils import summary, comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "path = ''\n",
    "image_path = os.path.join(path, './data/CameraRGB/')\n",
    "mask_path = os.path.join(path, './data/CameraMask/')\n",
    "image_list_orig = os.listdir(image_path)\n",
    "image_list = [image_path+i for i in image_list_orig]\n",
    "mask_list = [mask_path+i for i in image_list_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "img = imageio.imread(image_list[N])\n",
    "mask = imageio.imread(mask_list[N])\n",
    "#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
    "\n",
    "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
    "arr[0].imshow(img)\n",
    "arr[0].set_title('Image')\n",
    "arr[1].imshow(mask[:, :, 0])\n",
    "arr[1].set_title('Segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\n",
    "mask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)\n",
    "\n",
    "for path in zip(image_list_ds.take(3), mask_list_ds.take(3)):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames = tf.constant(image_list)\n",
    "masks_filenames = tf.constant(mask_list)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n",
    "\n",
    "for image, mask in dataset.take(1):\n",
    "    print(image)\n",
    "    print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=3)\n",
    "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
    "    return img, mask\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    input_image = tf.image.resize(image, (96, 128), method='nearest')\n",
    "    input_mask = tf.image.resize(mask, (96, 128), method='nearest')\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "image_ds = dataset.map(process_path)\n",
    "processed_image_ds = image_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "        \n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Add the first Conv2D layer\n",
    "    conv = Conv2D(n_filters,            # Number of filters\n",
    "                  (3, 3),               # Kernel size\n",
    "                  activation='relu',    # Activation function\n",
    "                  padding='same',       # Padding\n",
    "                  kernel_initializer='he_normal')(inputs)  # He initialization\n",
    "    \n",
    "    # Step 2: Add the second Conv2D layer\n",
    "    conv = Conv2D(n_filters,            # Number of filters\n",
    "                  (3, 3),               # Kernel size\n",
    "                  activation='relu',    # Activation function\n",
    "                  padding='same',       # Padding\n",
    "                  kernel_initializer='he_normal')(conv)  # He initialization\n",
    "    # Step 3: Add a Dropout layer if dropout_prob > 0\n",
    "    if dropout_prob > 0:\n",
    "        ### START CODE HERE\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "    # Step 4: Add MaxPooling2D if max_pooling is True\n",
    "    if max_pooling:\n",
    "    \n",
    "        next_layer = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    \n",
    "    # Step 5: Set skip_connection to conv (for potential skip connections in U-Net)\n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(96, 128, 3)\n",
    "n_filters = 32\n",
    "inputs = Input(input_size)\n",
    "cblock1 = conv_block(inputs, n_filters * 1)\n",
    "model1 = tf.keras.Model(inputs=inputs, outputs=cblock1)\n",
    "\n",
    "output1 = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
    "            ['Conv2D', (None, 96, 128, 32), 896, 'same', 'relu', 'HeNormal'],\n",
    "            ['Conv2D', (None, 96, 128, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
    "            ['MaxPooling2D', (None, 48, 64, 32), 0, (2, 2)]]\n",
    "\n",
    "print('Block 1:')\n",
    "for layer in summary(model1):\n",
    "    print(layer)\n",
    "\n",
    "comparator(summary(model1), output1)\n",
    "\n",
    "inputs = Input(input_size)\n",
    "cblock1 = conv_block(inputs, n_filters * 32, dropout_prob=0.1, max_pooling=True)\n",
    "model2 = tf.keras.Model(inputs=inputs, outputs=cblock1)\n",
    "\n",
    "output2 = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
    "            ['Conv2D', (None, 96, 128, 1024), 28672, 'same', 'relu', 'HeNormal'],\n",
    "            ['Conv2D', (None, 96, 128, 1024), 9438208, 'same', 'relu', 'HeNormal'],\n",
    "            ['Dropout', (None, 96, 128, 1024), 0, 0.1],\n",
    "            ['MaxPooling2D', (None, 48, 64, 1024), 0, (2, 2)]]\n",
    "           \n",
    "print('\\nBlock 2:')   \n",
    "for layer in summary(model2):\n",
    "    print(layer)\n",
    "    \n",
    "comparator(summary(model2), output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        expansive_input -- Input tensor from previous layer\n",
    "        contractive_input -- Input tensor from previous skip layer\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Add Conv2DTranspose layer to upsample the expansive_input\n",
    "    up = Conv2DTranspose(n_filters,                # Number of filters\n",
    "                         (3, 3),                  # Kernel size\n",
    "                         strides=(2, 2),          # Stride\n",
    "                         padding='same')(expansive_input)  # Padding\n",
    "\n",
    "    # Step 2: Concatenate the upsampled input with the contractive_input (skip connection)\n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "\n",
    "    # Step 3: Add two Conv2D layers with ReLU activation, same as in the contracting block\n",
    "    conv = Conv2D(n_filters,                      # Number of filters\n",
    "                  (3, 3),                         # Kernel size\n",
    "                  activation='relu',              # Activation\n",
    "                  padding='same',                 # Padding\n",
    "                  kernel_initializer='he_normal')(merge)  # He initialization\n",
    "\n",
    "    conv = Conv2D(n_filters,                      # Number of filters\n",
    "                  (3, 3),                         # Kernel size\n",
    "                  activation='relu',              # Activation\n",
    "                  padding='same',                 # Padding\n",
    "                  kernel_initializer='he_normal')(conv)  # He initialization\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size1=(12, 16, 256)\n",
    "input_size2 = (24, 32, 128)\n",
    "n_filters = 32\n",
    "expansive_inputs = Input(input_size1)\n",
    "contractive_inputs =  Input(input_size2)\n",
    "cblock1 = upsampling_block(expansive_inputs, contractive_inputs, n_filters * 1)\n",
    "model1 = tf.keras.Model(inputs=[expansive_inputs, contractive_inputs], outputs=cblock1)\n",
    "\n",
    "output1 = [['InputLayer', [(None, 12, 16, 256)], 0],\n",
    "            ['Conv2DTranspose', (None, 24, 32, 32), 73760],\n",
    "            ['InputLayer', [(None, 24, 32, 128)], 0],\n",
    "            ['Concatenate', (None, 24, 32, 160), 0],\n",
    "            ['Conv2D', (None, 24, 32, 32), 46112, 'same', 'relu', 'HeNormal'],\n",
    "            ['Conv2D', (None, 24, 32, 32), 9248, 'same', 'relu', 'HeNormal']]\n",
    "\n",
    "print('Block 1:')\n",
    "for layer in summary(model1):\n",
    "    print(layer)\n",
    "\n",
    "comparator(summary(model1), output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n",
    "    \"\"\"\n",
    "    Unet model\n",
    "    \n",
    "    Arguments:\n",
    "        input_size -- Input shape \n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        n_classes -- Number of output classes\n",
    "    Returns: \n",
    "        model -- tf.keras.Model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Contracting Path (encoding)\n",
    "    # Add a conv_block with the inputs of the unet_model and n_filters\n",
    "   \n",
    "    cblock1 = conv_block(inputs, n_filters)  # First conv block\n",
    "    cblock2 = conv_block(cblock1[0], n_filters * 2)  # Double filters for the next block\n",
    "    cblock3 = conv_block(cblock2[0], n_filters * 4)  # Double filters for the next block\n",
    "    cblock4 = conv_block(cblock3[0], n_filters * 8, dropout_prob=0.3)  # Dropout with 0.3\n",
    "    cblock5 = conv_block(cblock4[0], n_filters * 16, dropout_prob=0.3, max_pooling=False)  # No max pooling\n",
    "    ### END CODE HERE\n",
    "    \n",
    "    # Expanding Path (decoding)\n",
    "    # Add the first upsampling_block.\n",
    "    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
    " \n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters * 8)  # First upsampling\n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters * 4)  # Second upsampling\n",
    "    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters * 2)  # Third upsampling\n",
    "    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters)  # Fourth upsampling\n",
    "   \n",
    "\n",
    "    # Final convolutional layer\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                   (3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
    "   \n",
    "    conv10 = Conv2D(n_classes, (1, 1), padding='same')(conv9)  # Output layer\n",
    "  \n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import outputs\n",
    "img_height = 96\n",
    "img_width = 128\n",
    "num_channels = 3\n",
    "\n",
    "unet = unet_model((img_height, img_width, num_channels))\n",
    "comparator(summary(unet), outputs.unet_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 96\n",
    "img_width = 128\n",
    "num_channels = 3\n",
    "\n",
    "unet = unet_model((img_height, img_width, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in image_ds.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    print(mask.shape)\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in processed_image_ds.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    print(mask.shape)\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "VAL_SUBSPLITS = 5\n",
    "BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "print(processed_image_ds.element_spec)\n",
    "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    \"\"\"\n",
    "    Displays the first image of each of the num batches\n",
    "    \"\"\"\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = unet.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(train_dataset, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
